{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPYoPuJrpw9xfG7zLQMkIgu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ngolla/video-captioning/blob/master/Copy_of_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrPN9uqnfk14"
      },
      "source": [
        "import pickle\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-mIiG7if7KI",
        "outputId": "d8023d21-928f-446d-8d3b-475070df5ccf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhmuHrUBfsIq",
        "outputId": "871d0102-ae1c-4746-e0b5-2f8777b96b25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "drive_path=Path('/content/drive/My Drive')\n",
        "list(drive_path.glob('*'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/content/drive/My Drive/Colab Notebooks'),\n",
              " PosixPath('/content/drive/My Drive/YouTubeClips.tar'),\n",
              " PosixPath('/content/drive/My Drive/video_corpus.csv'),\n",
              " PosixPath('/content/drive/My Drive/.ipynb_checkpoints'),\n",
              " PosixPath('/content/drive/My Drive/VideoArrays'),\n",
              " PosixPath('/content/drive/My Drive/model1.h5'),\n",
              " PosixPath('/content/drive/My Drive/splitdata'),\n",
              " PosixPath('/content/drive/My Drive/splitset'),\n",
              " PosixPath('/content/drive/My Drive/test.dat'),\n",
              " PosixPath('/content/drive/My Drive/tokens_word_index.txt'),\n",
              " PosixPath('/content/drive/My Drive/tokens_index_word.txt')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfj3Hbsc8dsj",
        "outputId": "38bcf9a5-cb58-41e7-9769-bb0a5682f242",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "split_path=drive_path.joinpath('splitset')\n",
        "list(split_path.glob('*'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/content/drive/My Drive/splitset/train.dat'),\n",
              " PosixPath('/content/drive/My Drive/splitset/test.dat'),\n",
              " PosixPath('/content/drive/My Drive/splitset/tokens_word_index.txt'),\n",
              " PosixPath('/content/drive/My Drive/splitset/tokens_index_word.txt')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4DFcDBVgJjN"
      },
      "source": [
        "train_file=split_path.joinpath('train.dat')\n",
        "val_file=split_path.joinpath('test.dat')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9V50lM_khIIj"
      },
      "source": [
        "(vid_val, cap_val)=pickle.load(open( val_file, \"rb\" ))\n",
        "(vid_train, cap_train)=pickle.load(open( train_file, \"rb\" ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1fjJ4jJh8xV",
        "outputId": "3acf74f4-b5e9-4604-e5ab-d43d81807124",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(vid_train), vid_train[0].shape)\n",
        "print(len(vid_val), vid_val[0].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8000 (80, 4096)\n",
            "2000 (80, 4096)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aseWEIYkO6u"
      },
      "source": [
        "vid_train=np.array(vid_train)\n",
        "cap_train=np.array(cap_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfxudfOm9Nlh"
      },
      "source": [
        "vid_val=np.array(vid_val)\n",
        "#cap_val=np.array(cap_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0XGB80vOaif"
      },
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense\n",
        "\n",
        "# returns train, inference_encoder and inference_decoder models\n",
        "def basic_enc_dec(n_input, n_output, n_units):\n",
        "    # define training encoder\n",
        "    encoder_inputs = Input(shape=(None, n_input))\n",
        "    encoder = LSTM(n_units, return_state=True)\n",
        "    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "    encoder_states = [state_h, state_c]\n",
        "\n",
        "    # define training decoder\n",
        "    decoder_inputs = Input(shape=(None, n_output))\n",
        "    decoder_lstm = LSTM(n_units, return_sequences=True, return_state=True)\n",
        "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "    decoder_dense = Dense(n_output, activation='softmax')\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "    # define inference encoder\n",
        "    encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "    # define inference decoder\n",
        "    decoder_state_input_h = Input(shape=(n_units,))\n",
        "    decoder_state_input_c = Input(shape=(n_units,))\n",
        "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "    decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "    decoder_states = [state_h, state_c]\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "    decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
        "\n",
        "    # return all models\n",
        "    return model, encoder_model, decoder_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwz87-p5_xBa",
        "outputId": "75361bee-6345-44ec-878b-e322dfafe5a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#split_path.joinpath('tokens_word_index.txt')\n",
        "token=pickle.load(open(split_path.joinpath('tokens_word_index.txt'),\"rb\"))\n",
        "len(token.items())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3434"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kig2IfhK--t5",
        "outputId": "d09f98a8-3031-417a-bf5a-a225ec75a994",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cap_train[0].shape[0], vid_train.shape[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35, 4096)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZCNXTxO8TIF"
      },
      "source": [
        "vocab_size=len(token.items())+1\n",
        "#dim_embedding=64\n",
        "maxlen=cap_train[0].shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLrUkyMtP9eB"
      },
      "source": [
        "model, enc, dec = basic_enc_dec(vid_train.shape[2], vocab_size, maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONBT2OObRweP",
        "outputId": "6d56e797-c20b-466f-c023-7feef9fb15ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, 4096)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None, 3435)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 35), (None,  578480      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 35), ( 485940      input_2[0][0]                    \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 3435)   123660      lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 1,188,080\n",
            "Trainable params: 1,188,080\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwjlpmOmUPd2"
      },
      "source": [
        "x2 = np.hstack([np.zeros((len(cap_train), 1)), cap_train])\n",
        "x2 = x2[:, :-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqjYxJffU9v2"
      },
      "source": [
        "#Convert to (no of captions)x(no of words)x(vocab size)\n",
        "from keras.utils.np_utils import to_categorical   \n",
        "\n",
        "#x2_in = to_categorical(x2, num_classes = vocab_size)\n",
        "x2 = to_categorical(x2, num_classes = vocab_size)\n",
        "outputs = to_categorical(cap_train, num_classes = vocab_size)\n",
        "#print(x2_in.shape, outputs.shape)\n",
        "print(x2.shape, outputs.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDQo77chVV9b"
      },
      "source": [
        "del cap_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZmIxq82RC3t"
      },
      "source": [
        "x2_val = np.hstack([np.zeros((cap_val.shape[0], 1)), cap_val])\n",
        "x2_val = x2_val[:, :-1]\n",
        "\n",
        "x2_val = to_categorical(x2_val, num_classes = vocab_size)\n",
        "outputs_val = to_categorical(cap_val, num_classes = vocab_size)\n",
        "\n",
        "print(x2_val.shape, outputs_val.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NWKDoDZVYyH"
      },
      "source": [
        "del cap_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtkickzwVD5l"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "model.compile(optimizer=RMSprop(lr=7e-4), loss='categorical_crossentropy')\n",
        "#history=model.fit([vid, x2_in], outputs, epochs = 1)\n",
        "callback = EarlyStopping(monitor='loss', patience=3)\n",
        "history=model.fit([vid_train, x2], outputs, validation_data=([vid_val, x2_val], outputs_val), epochs = 100,callbacks=[callback], verbose=0)\n",
        "#history=model.fit([vid_train, x2_in],outputs,batch_size=100,epochs=1, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC0AjKmHSYfq"
      },
      "source": [
        " This callback will stop the training when there is no improvement in  the validation loss for three consecutive epochs. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "475pd_hwVzjz"
      },
      "source": [
        "history.history\n",
        "model.save(split_path.joinpath('model_100.h5'))\n",
        "enc, dec\n",
        "enc.save(split_path.joinpath('encoder.h5'))\n",
        "dec.save(split_path.joinpath('decoder.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}